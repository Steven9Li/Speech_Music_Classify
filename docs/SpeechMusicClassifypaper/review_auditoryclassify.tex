\documentclass[11pt]{article}
\usepackage{parskip}
\usepackage{color}

\title{Neural-based auditory classification, review}
\author{Nate Zuk}

\begin{document}
\maketitle

\textbf{Zatorre, Belin (2001) "Spectral and temporal processing in human auditory cortex", \textit{Cereb Cortex}}

Subjects listened to stimuli that varied in timing of two tones (fast or slow rate of switching) or varied in the number of tones presented isochronously (see Fig. 1).  In all conditions, tones were between 500 and 1000 Hz.  The authors measured cerebral blood flow (CBF) during these presentations and analyzed the relationship between CBF and the temporal and spectral variability in stimuli.  Anterior STS on both sides of the head and right STG was correlated with temporal and spectral variation (Fig. 2).  They also found that the right STS covaried more with the spectral changes than temporal, and left STS covaried more with temporal changes than spectral (Fig 3 \& 4).  They use this result as evidence for hemispheric differences in representing sound.

\textbf{Zatorre, Belin, Penhune (2002) "Structure and function of auditory cortex: music and speech", \textit{Trends Cogn Sci}, review}

Examine the differences in speech and music and how that may be reflected by what is currently known about the neural processing of sounds.

Melodies with note durations shorter than 160 ms are hard to identify \textcolor{red}{(Warren et al, 1991, Music Percept)}.

They also cite many studies (25-48) that show pitch processing and spectral processing is predominantly done by the right hemisphere, via lesion studies and imaging studies.

Suggest that hemispheric differences may "stem from the fundamentally different computational demands made by environmental signals" like speech and music, where acoustic parameters like timing and pitch carry different relative importance (p. 40).  If temporal information comes at the expense of pitch (spectral) information and vice versa, then it might be optimal to have two separate processing streams where each type of information is optimized.

\textcolor{blue}{The trade-off of temporal and spectral information in a signal is mathematical in origin and called "Gabor's uncertainty principle" (inpsired by Heisenberg's uncertainty principle).  Oxenham's work has made it pretty clear that cochlear place information is necessary for perceiving pitch.}

\textbf{Zatorre, Bouffard, Belin (2004) "Sensitivity to auditory object features in human
temporal neocortex", \textit{J Neurosci}}

Subjects listened to 500 ms long sounds that were presented in isolation or combined with other sounds.  There were 45 unique sounds in total in their set of stimuli.  When there are more sounds presented simultaneously, it becomes difficult for the listener to distinguish between different mixtures with the same number of sounds (Fig. 2).  They used the behavioral distinguishability rating to quantify related changes in cerebral blood flow, measured using PET scans.  Right STS and right IFG showed more activity for distinguishable sounds compared to similar sounds (Fig. 3).  Right STS activity was correlated with the distinguishability behavioral measure (Fig. 4).

\textcolor{See also:}

\begin{itemize}
\item Zatorre RJ, Belin P, Penhune VB (2002a) Structure and function of auditory cortex: music and speech. Trends Cognit Sci 6:37â€“46.
\end{itemize}

\end{document}